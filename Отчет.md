Запрос 1.
    План запроса со статистикой выполнения до изменений:
                                                 QUERY PLAN                                             
    ----------------------------------------------------------------------------------------------------
     Seq Scan on t1  (cost=0.00..208393.83 rows=1 width=30) (actual time=8.241..616.528 rows=1 loops=1)
       Filter: (id = 50000)
       Rows Removed by Filter: 9999999
     Planning Time: 0.283 ms
     Execution Time: 616.564 ms
    (5 rows)

    План запроса со статистикой выполнения после изменений:
                                                          QUERY PLAN                                                   
    ---------------------------------------------------------------------------------------------------------------
     Index Scan using t1_id_idx on t1  (cost=0.43..8.45 rows=1 width=30) (actual time=0.010..0.010 rows=1 loops=1)
       Index Cond: (id = 50000)
     Planning Time: 0.192 ms
     Execution Time: 0.046 ms
    (4 rows)
    
    Изначально запрос медленно выполняется, т.к. выполняется последовательный скан таблицы (Seq Scan on t1), то есть проверяется каждая запись на соответствие условию id = 50000.
    Чтобы ускорить запрос создадим индекс на столбец id таблицы t1 для ускорения доступа к данным (Index Scan using t1_id_idx on t1). PostgreSQL строит B-дерево, в котором id - ключи, 
    а значения - ссылки на соответствующие строки таблицы. При выполнении запроса where id = 50000, PostgreSQL просто спускается по дереву к нужному узлу, не просматривая другие записи.
    С помощью команды analyze t1 PostgreSQL собирает статическую информацию о таблице и ее содержимом, что помогает оптимизатору запросов выбрать наиболее эффективный план выполнения.
    
Запрос 2.
    План запроса со статистикой выполнения до изменений:
                                                              QUERY PLAN                                                           
    -------------------------------------------------------------------------------------------------------------------------------
     Aggregate  (cost=385689.51..385689.52 rows=1 width=32) (actual time=4044.066..4044.069 rows=1 loops=1)
       Buffers: shared hit=4256 read=111008, temp read=17852 written=17852
       ->  Hash Left Join  (cost=218337.69..373189.28 rows=5000090 width=9) (actual time=949.998..3225.043 rows=5000000 loops=1)
             Hash Cond: (t2.t_id = t1.id)
             Buffers: shared hit=4256 read=111008, temp read=17852 written=17852
             ->  Seq Scan on t2  (cost=0.00..81872.90 rows=5000090 width=13) (actual time=0.133..466.787 rows=5000000 loops=1)
                   Buffers: shared hit=2080 read=29792
             ->  Hash  (cost=208393.83..208393.83 rows=606069 width=4) (actual time=945.141..945.143 rows=625117 loops=1)
                   Buckets: 262144  Batches: 4  Memory Usage: 7557kB
                   Buffers: shared hit=2176 read=81216, temp written=1371
                   ->  Seq Scan on t1  (cost=0.00..208393.83 rows=606069 width=4) (actual time=0.140..845.545 rows=625117 loops=1)
                         Filter: (name ~~ 'a%'::text)
                         Rows Removed by Filter: 9374883
                         Buffers: shared hit=2176 read=81216
     Planning:
       Buffers: shared hit=174
     Planning Time: 3.280 ms
     Execution Time: 4044.556 ms
    (18 rows)

    План запроса со статистикой выполнения после изменений:
                                                                                      QUERY PLAN                                                                         
           
    -------------------------------------------------------------------------------------------------------------------------------------------------------------------
    -------
     Finalize Aggregate  (cost=134925.89..134925.90 rows=1 width=32) (actual time=781.044..787.156 rows=1 loops=1)
       Buffers: shared hit=10285 read=20865
       ->  Gather  (cost=134925.26..134925.87 rows=6 width=32) (actual time=780.801..787.140 rows=7 loops=1)
             Workers Planned: 6
             Workers Launched: 6
             Buffers: shared hit=10285 read=20865
             ->  Partial Aggregate  (cost=133925.26..133925.27 rows=1 width=32) (actual time=775.529..775.533 rows=1 loops=7)
                   Buffers: shared hit=10285 read=20865
                   ->  Merge Left Join  (cost=2.76..131841.93 rows=833332 width=9) (actual time=0.455..521.309 rows=714286 loops=7)
                         Merge Cond: (t2.t_id = t1.id)
                         Buffers: shared hit=10285 read=20865
                         ->  Parallel Index Only Scan using t2_tidday_idx on t2  (cost=0.43..110245.71 rows=833332 width=13) (actual time=0.076..178.677 rows=714286 lo
    ops=7)
                               Heap Fetches: 0
                               Buffers: shared hit=10 read=19157
                         ->  Index Only Scan using t1_idname_idx on t1  (cost=0.42..17157.88 rows=707076 width=4) (actual time=0.071..128.285 rows=624257 loops=7)
                               Heap Fetches: 0
                               Buffers: shared hit=10275 read=1708
     Planning:
       Buffers: shared hit=96 read=7
     Planning Time: 0.596 ms
     Execution Time: 787.221 ms
    (21 rows)

    Изначально запрос медленно выполняется, т.к. выполняется последовательный скан таблиц t1 и t2, а также используется Hash Left Join. Долго строится хэш-таблица, плюс т.к. таблица
    большая, PostgreSQL не может держать всю ее в оперативной памяти, и она выгружается на диск, что тоже замедляет выполнение.
    Для ускорения создадим индекс on t1(id) where name like 'a%' для фильтрации данных по этому условию и для более быстрого поиска строк из t1, соответствующих строкам из t2.
    Создадим индекс on t2(t_id, day) для соединения с таблицей t1 и для более быстрого поиска строк.
    Запретим использование полного скана таблиц и hashjoin. Увеличим максимальное количество параллельных рабочих процессов до 6. 
    Установим размер памяти, который PostgreSQL сможет использовать для операций сортировки и хеширования work_mem = 32MB.
    Используем команду analyze table.
    В итоге используется Merge Left Join (быстрее работает при использовании индексов, не требует загрузки всей таблицы в ОП), Index Only Scan (читаются только индексы, без обращения 
    к самой таблице)
    
Запрос 3:
    Не дождался пока закончится выполнения запроса до изменений...
    План запроса со статистикой выполнения после изменений:
                                                                                QUERY PLAN                                                                    
    -------------------------------------------------------------------------------------------------------------------------------------------------
     Index Only Scan using t2_tidday_idx on t2  (cost=284690.27..449102.13 rows=2499996 width=9) (actual time=6349.456..6349.457 rows=0 loops=1)
       Filter: (NOT (hashed SubPlan 1))
       Rows Removed by Filter: 5000000
       Heap Fetches: 0
       Buffers: shared hit=4 read=46485
       SubPlan 1
         ->  Index Only Scan using t1_id_idx on t1  (cost=0.43..259689.64 rows=10000080 width=4) (actual time=0.064..1190.974 rows=10000000 loops=1)
               Heap Fetches: 0
               Buffers: shared hit=3 read=27325
     Planning:
       Buffers: shared hit=29 read=2
     Planning Time: 0.274 ms
     Execution Time: 6382.968 ms
    (13 rows)
    
    Изначально запрос меделенно работает, т.к. выполняется последовательный скан таблиц t1 и t2, а также выделяется недостаточно work_mem, из-за чего происходит много обращений к диску.
    Добавим индексы on t1(id) и t2(t_id, day), чтобы использовался Index Only Scan.
    Запретим использовать последовательный скан таблиц.
    Установим work_mem = 256MB;

Запрос 4:
    Также не дождался завершения запроса до изменений.
    План запроса со статистикой выполнения после изменений:
                                                                    QUERY PLAN                                                                
    ------------------------------------------------------------------------------------------------------------------------------------------
     Index Only Scan using t2_tidday_idx on t2  (cost=0.44..2156943.91 rows=415571 width=9) (actual time=0.150..1977.636 rows=823592 loops=1)
       Index Cond: (day > to_char(date_trunc('day'::text, (now() - '1 mon'::interval)), 'yyyymmdd'::text))
       Filter: (SubPlan 1)
       Heap Fetches: 0
       SubPlan 1
         ->  Index Only Scan using t1_id_idx on t1  (cost=0.43..4.45 rows=1 width=4) (actual time=0.001..0.001 rows=1 loops=823592)
               Index Cond: (id = t2.t_id)
               Heap Fetches: 0
     Planning Time: 0.591 ms
     Execution Time: 2005.004 ms
    (10 rows)
    
    Изначально запрос меделенно работает, т.к. выполняется последовательный скан таблиц t1 и t2.
    Добавим индексы on t1(id) и t2(t_id, day), чтобы использовался Index Only Scan.
    Планировщик сам решает не использовать последовательный скан таблиц.
    Установим work_mem = 256MB;
    
Задание 5.
    Статистика после 5 минут нагрузки до изменений:
        pg_stat_bgwriter:
     checkpoints_timed | checkpoints_req | checkpoint_write_time | checkpoint_sync_time | buffers_checkpoint | buffers_clean | maxwritten_clean | buffers_backend | buffers_backend_fsync | buffers_alloc |
    -------------------+-----------------+-----------------------+----------------------+--------------------+---------------+------------------+-----------------+-----------------------+---------------+
                     1 |               0 |                  1021 |                   20 |                  8 |           915 |                0 |              16 |                     0 |       4108332 |
              
    checkpoints_timed - количество запланированных контрольных точек, которые уже были выполнены;
    checkpoints_req - количество запрошенных контрольных точек, которые уже были выполнены. Было три точки из-за переполнения WAL;
    checkpoint_write_time - общее время, которое было затрачено на этап обработки контрольной точки, в котором файлы записываются на диск, в миллисекундах;
    checkpoint_sync_time - общее время, которое было затрачено на этап обработки контрольной точки, в котором файлы синхронизируются с диском, в миллисекундах;
    buffers_checkpoint - количество буферов, записанных при выполнении контрольных точек;
    buffers_clean - количество буферов, записанных фоновым процессом записи;
    maxwritten_clean - сколько раз фоновый процесс записи останавливал сброс грязных страниц на диск из-за того, что записал слишком много буферов;
    buffers_backend - количество буферов, записанных самим серверным процессом;
    buffers_backend_fsync - сколько раз серверному процессу пришлось выполнить fsync самостоятельно;
    buffers_alloc - количество выделенных буферов.
    
    За 5 минут только пару раз tps был не равен нулю, но и не превышал 3. Т.к. нет индекса, то update происходит очень долго из-за поиска нужной строки.

    
    Увеличим shared_buffers до 1GB, т.к. выделяется слишком много буферов.
    Создадим индекс on t1(id).
    
    Статистика после 5 минут нагрузки после вышеперечисленных изменений:
        pg_stat_bgwriter:
 checkpoints_timed | checkpoints_req | checkpoint_write_time | checkpoint_sync_time | buffers_checkpoint | buffers_clean | maxwritten_clean | buffers_backend | buffers_backend_fsync | buffers_alloc |
-------------------+-----------------+-----------------------+----------------------+--------------------+---------------+------------------+-----------------+-----------------------+---------------+
                 0 |               3 |                178294 |                  325 |             132482 |         22742 |              124 |           63630 |                     0 |        148558 |
    
    tps первых 10 секунд:
    progress: 1.0 s, 0.0 tps, lat 0.000 ms stddev 0.000, 0 failed
    progress: 2.0 s, 80.1 tps, lat 238.964 ms stddev 372.991, 0 failed
    progress: 3.0 s, 165.0 tps, lat 59.904 ms stddev 15.689, 0 failed
    progress: 4.0 s, 182.0 tps, lat 55.782 ms stddev 13.768, 0 failed
    progress: 5.0 s, 176.0 tps, lat 55.639 ms stddev 11.646, 0 failed
    progress: 6.0 s, 178.0 tps, lat 56.110 ms stddev 12.548, 0 failed
    progress: 7.0 s, 182.0 tps, lat 55.451 ms stddev 13.800, 0 failed
    progress: 8.0 s, 181.0 tps, lat 55.101 ms stddev 11.307, 0 failed
    progress: 9.0 s, 179.0 tps, lat 55.409 ms stddev 11.579, 0 failed
    progress: 10.0 s, 182.0 tps, lat 55.577 ms stddev 11.839, 0 failed

    Увеличим max_wal_size до 2 GB, т.к. значение checkpoint_write_time велико.
    Увеличим bgwriter_lru_maxpages до 1000, чтобы уменьшить buffers_backend.
    
    Статистика после 5 минут нагрузки после всех изменений:
        pg_stat_bgwriter:
 checkpoints_timed | checkpoints_req | checkpoint_write_time | checkpoint_sync_time | buffers_checkpoint | buffers_clean | maxwritten_clean | buffers_backend | buffers_backend_fsync | buffers_alloc |
-------------------+-----------------+-----------------------+----------------------+--------------------+---------------+------------------+-----------------+-----------------------+---------------+
                 1 |               1 |                269956 |                   58 |             103307 |         35106 |              322 |             906 |                     0 |        161321 |
    
    tps первых 10 секунд:
    progress: 1.0 s, 0.0 tps, lat 0.000 ms stddev 0.000, 0 failed
    progress: 2.0 s, 64.4 tps, lat 298.323 ms stddev 428.724, 0 failed
    progress: 3.0 s, 186.0 tps, lat 53.430 ms stddev 12.262, 0 failed
    progress: 4.0 s, 185.0 tps, lat 53.946 ms stddev 11.561, 0 failed
    progress: 5.0 s, 194.0 tps, lat 52.249 ms stddev 10.899, 0 failed
    progress: 6.0 s, 190.0 tps, lat 51.944 ms stddev 11.266, 0 failed
    progress: 7.0 s, 191.0 tps, lat 52.519 ms stddev 10.484, 0 failed
    progress: 8.0 s, 179.0 tps, lat 55.782 ms stddev 15.683, 0 failed
    progress: 9.0 s, 183.0 tps, lat 52.069 ms stddev 10.770, 0 failed
    progress: 10.0 s, 177.0 tps, lat 58.268 ms stddev 46.472, 0 failed
    

